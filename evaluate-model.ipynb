{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install einops pytorch_lightning diffusers==0.12.1 kornia librosa accelerate ipympl nussl pandas==1.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T11:26:08.687107Z",
     "iopub.status.busy": "2023-06-12T11:26:08.686482Z",
     "iopub.status.idle": "2023-06-12T11:26:11.558575Z",
     "shell.execute_reply": "2023-06-12T11:26:11.557790Z",
     "shell.execute_reply.started": "2023-06-12T11:26:08.687078Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from src import *\n",
    "from dataset import SpectrogramDataset\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds=SpectrogramDataset(target_dir='datasets/randomMIDI/PianoViolin11025/WAV/train/ins3',\n",
    "                            condition_dir='datasets/randomMIDI/PianoViolin11025/WAV/train/mix',\n",
    "                            return_pair=True\n",
    "                     )\n",
    "\n",
    "\n",
    "valid_ds=SpectrogramDataset(target_dir='datasets/randomMIDI/PianoViolin11025/WAV/val/ins3',\n",
    "                          condition_dir='datasets/randomMIDI/PianoViolin11025/WAV/val/mix',\n",
    "                          return_pair=True\n",
    "                     )\n",
    "\n",
    "test_ds=SpectrogramDataset(target_dir='datasets/randomMIDI/PianoViolin11025/WAV/test/ins3',\n",
    "                           condition_dir='datasets/randomMIDI/PianoViolin11025/WAV/test/mix',\n",
    "                           return_pair=True\n",
    "                     )\n",
    "\n",
    "condition, target = test_ds[0]\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(condition.permute(1,2,0))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(target.permute(1,2,0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.out_channels, valid_ds.out_channels, test_ds.out_channels = (1,1,1)\n",
    "train_ds.return_mask, valid_ds.return_mask, test_ds.return_mask = (False, False, False)\n",
    "\n",
    "model_path = '/notebooks/trained_models/diffusion/L1/lightning_logs/version_25/'\n",
    "model = PixelDiffusionConditional.load_from_checkpoint(model_path+'checkpoints/epoch=1999-step=126620.ckpt', train_dataset = test_ds).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.out_channels, valid_ds.out_channels, test_ds.out_channels = (3,3,3)\n",
    "train_ds.return_mask, valid_ds.return_mask, test_ds.return_mask = (False, False, False)\n",
    "\n",
    "autoencoder = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-ema\")\n",
    "pl_ae_model = Autoencoder(autoencoder).to(device)\n",
    "model_path = 'trained_models/mask_latent_diffusion/lightning_logs/version_1/'\n",
    "model = LatentDiffusionConditional.load_from_checkpoint(model_path + 'checkpoints/epoch=1523-step=48768.ckpt', train_dataset = test_ds, autoencoder = pl_ae_model).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.out_channels, valid_ds.out_channels, test_ds.out_channels = (3,3,3)\n",
    "train_ds.return_mask, valid_ds.return_mask, test_ds.return_mask = (True, True, True)\n",
    "\n",
    "autoencoder = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-ema\")\n",
    "pl_ae_model = Autoencoder(autoencoder).to(device)\n",
    "model_path = 'trained_models/mask_latent_diffusion/lightning_logs/version_1/'\n",
    "model = LatentDiffusionConditional.load_from_checkpoint(model_path + 'checkpoints/epoch=1523-step=48768.ckpt', train_dataset = test_ds, autoencoder = pl_ae_model).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.out_channels, valid_ds.out_channels, test_ds.out_channels = (1,1,1)\n",
    "train_ds.return_mask, valid_ds.return_mask, test_ds.return_mask = (True, True, True)\n",
    "\n",
    "model_path = '/notebooks/trained_models/UNet/L1/lightning_logs/version_5/'\n",
    "model = plUnet.load_from_checkpoint(model_path+'checkpoints/epoch=1999-step=126620.ckpt', train_dataset = test_ds).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-12T12:22:31.256562Z",
     "iopub.status.busy": "2023-06-12T12:22:31.256050Z",
     "iopub.status.idle": "2023-06-12T12:22:33.190917Z",
     "shell.execute_reply": "2023-06-12T12:22:33.189868Z",
     "shell.execute_reply.started": "2023-06-12T12:22:31.256519Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "\n",
    "model_path_1='/notebooks/trained_models/diffusion/L1/lightning_logs'\n",
    "model_path_2='/notebooks/trained_models/latent_diffusion/L1/lightning_logs'\n",
    "model_path_3='/notebooks/trained_models/mask_latent_diffusion/L1/lightning_logs'\n",
    "\n",
    "model_paths = [model_path_1, model_path_2, model_path_3]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, sharey=True, sharex=True, figsize=(9,3))\n",
    "\n",
    "\n",
    "for model in range(len(model_paths)):\n",
    "\n",
    "    summary_iterators = [EventAccumulator(os.path.join(model_paths[model], dname)).Reload() for dname in os.listdir(model_paths[model])]\n",
    "\n",
    "\n",
    "    tags = summary_iterators[0].Tags()['scalars']\n",
    "\n",
    "    valsteps = []\n",
    "    valvalues = []\n",
    "    trainsteps = []\n",
    "    trainvalues = []\n",
    "\n",
    "    for ver in summary_iterators:\n",
    "        if all(tag in ver.Tags()['scalars'] for tag in tags):\n",
    "            valsteps.extend([e.step/63 for e in ver.Scalars('val_loss')])\n",
    "            valvalues.extend([e.value for e in ver.Scalars('val_loss')])\n",
    "            trainsteps.extend([e.step/63 for e in ver.Scalars('val_loss')])\n",
    "            trainvalues.extend([e.value for e in ver.Scalars('train_loss')])\n",
    "\n",
    "    valsteps,valvalues = zip(*sorted(zip(valsteps,valvalues)))\n",
    "    trainsteps,trainvalues = zip(*sorted(zip(trainsteps,trainvalues)))\n",
    "\n",
    "    axs[model].plot(valsteps,valvalues, label='Validation loss')\n",
    "    axs[model].plot(trainsteps,trainvalues, label='Train loss')\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Epoch', ylabel='L1 Loss')\n",
    "    ax.set_yscale('log')\n",
    "    ax.label_outer()\n",
    "\n",
    "axs[0].set_title('Standard Diffusion')\n",
    "axs[1].set_title('Latent Diffusion')\n",
    "axs[2].set_title('Mask Latent Diffusion')\n",
    "    \n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import nussl\n",
    "import nussl.evaluation as ne\n",
    "\n",
    "\n",
    "outputs = []\n",
    "targets = []\n",
    "\n",
    "for i in range(2):\n",
    "    mix = test_ds[i][0]\n",
    "    out = model(mix.unsqueeze(0), verbose=True).detach().cpu()\n",
    "    out = out[0]\n",
    "    phase = test_ds.get_phase(i)\n",
    "\n",
    "    estimated_source = out * test_ds[i][0]\n",
    "    target_source = test_ds[i][1]\n",
    "\n",
    "    mix = nussl.AudioSignal(audio_data_array=test_ds.to_audio(mix, phase), sample_rate=11025)\n",
    "    estimated_source = nussl.AudioSignal(audio_data_array=test_ds.to_audio(estimated_source, phase), sample_rate=11025)\n",
    "    target_source = nussl.AudioSignal(audio_data_array=test_ds.to_audio(target_source, phase), sample_rate=11025)\n",
    "\n",
    "    target_rest = mix - target_source\n",
    "    estimated_rest = mix - estimated_source\n",
    "\n",
    "    estimates = [estimated_source, estimated_rest]\n",
    "    targets = [target_source, target_rest]\n",
    "\n",
    "    evaluator = ne.BSSEvalScale(targets, estimates, ['ins3', 'rest'])\n",
    "    scores = evaluator.evaluate()\n",
    "\n",
    "    os.makedirs(model_path + 'scores/', exist_ok=True)\n",
    "    output_file = model_path + 'scores/' + test_ds.files[i].replace('wav', 'json')\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "json_files = glob.glob(str(model_path) + 'scores/*.json')\n",
    "\n",
    "df = ne.aggregate_score_files(json_files, aggregator=np.nanmedian)\n",
    "report_card = ne.report_card(df, report_each_source=True)\n",
    "print(report_card)\n",
    "with open(model_path + 'report_card.json', 'w') as f:\n",
    "    json.dump(report_card, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
